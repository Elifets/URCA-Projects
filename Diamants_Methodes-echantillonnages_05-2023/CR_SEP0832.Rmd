---
documentclass: "compterendu"
lang: true
babel-lang: "french"
geometry:
  - left=2cm
  - right=2cm
  - top=2.5cm
  - bottom=2.5cm
title: "Projet sur les méthodes d'échantillonnage"
author: 
  - Elif ERTAS
  - Fatima AAGOUR
  - Ibrahima TANDIA 
  - Aldjia IBEGHOUCHENE
email: 
  - elif.ertas@etudiant.univ-reims.fr
  - fatima.aagour@etudiant.univ-reims.fr
  - ibrahima.tandia@etudiant.univ-reims.fr
  - aldjia.ibeghouchene@etudiant.univ-reims.fr
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: "Ce projet présente les différentes méthodes de reéchantionnage, de validation croisée et de bootsrtap pour l'estimation de l'erreur en régression."
keywords:
  - Regression
  - Prediction 
  - Erreur 
git: "https://github.com/pregnault/urcadown"
database: "https://bookdown.org/yih_huynh/Guide-to-R-Book/diamonds.html"
anac: "2022-2023"
diplome: "Master de mathématiques appliquées, 1\\up{ème} année"
module: "SEP0832"
enseig: "Amor Keziou"
evaluation: "Compte-rendu d'analyse"
coefficient: "50 \\%"
output: 
  bookdown::pdf_book:
    citation_package: biblatex
    template: template.tex
    fig_caption: yes
    keep_tex: yes
    toc: yes
biblatex: true
bibliography: biblio-cr-urca.bib
biblio-style : alphabetic
link-citations: yes
---

# Introduction 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
rm(list = ls()) # vider la memoire 
library(ggplot2)
library(dplyr)
library(knitr)
library(lmtest)
library(glmulti)
library(boot)
```

```{r, echo = FALSE, include = FALSE}
#Ce bloc configure quelques options d'affichage pour les blocs R
opts_chunk$set(comment = '', echo = FALSE,  tidy = TRUE, fig.align='center', fig.width= 4.5, fig.height = 3.2)
knit_theme$set("moe")
```

Dans le cadre de ce projet, nous allons étudier la variation de prix sur des diamands en fonction de leurs nombreuses caractéristiques telles que la taille, le poids ou leur couleur.   
    
Nous cherchons donc à trouver une solution à la problématique suivante :    

$$ \textbf{Comment peut-on expliquer le prix d'un diamands en fonction de ses caractéristiques ?} $$
    
Afin de répondre à notre problématique, nous allons mettre en place des modèles de régressions linéaires multiples puis nous chercherons le meilleur modèle qui décrit au mieux la variable expliquée __price__ .    
     
Notre travail se divisera en 3 étapes : la construction du modèle de régression linéaire multiple complet et la vérification de ses hypothèses, la sélection des meilleurs modèles et l’estimation de l’erreur de prévision de ces derniers afin de sélectionner le meilleur.    
     
En ce qui concerne la répartition des tâches, voici ce que chacun d'entre nous à apporter :    

\begin{itemize}
  \item Fatima : Recherche de la base de donnée, construction du modèle RLM et vérification des hypothèses d'homoscédasticité et d'auto-corrélation, analyse des résidus, sélection du meilleur modèle avec la méthode exhaustive.  
  \item Elif : Rédaction et mise en page, explication de la base de donnée, vérification des hypothèses de linéarité et de normalité, influence des outliers, sélection du meilleur modèle avec la méthode génétique, conclusion. 
  \item Aldjia : Estimation de l'erreur de prévision par l'approche de l'ensemble de validation, leave-one-out VC et K-fold CV pour chacun des modèles, mise en place de l’outil bootstrap. 
  \item Ibrahima : Interprétation du bootstrap. 
\end{itemize}


# Explication de la base de donnée 

La base de données __diamonds__ est une collection de données réelles sur les caractéristiques et les prix de plus de 50 000 diamants. Elle contient notamment leur poids, leur qualité de coupe, leur couleur, leur pureté et leur prix. Les données ont été recueillies auprès de détaillants de diamants aux États-Unis par la société d'analyse des données Tippes et reprises par ggplot2, une bibliothèque de visualisation de données de R.  
  
Les diamants inclus dans la base de données ont été sélectionnés de manière aléatoire à partir d'un échantillon représentatif de diamants disponibles sur le marché. Les caractéristiques des diamants ont été évaluées et mesurées par des gemmologues professionnels, et les prix ont été enregistrés par les détaillants.  
  
Les informations contenues dans cette base de données sont utilisées pour prédire le prix des diamants en fonction de leurs caractéristiques. L'analyse des données de cette base peut aider à comprendre les facteurs qui influencent le prix des diamants et peut être utile pour les acheteurs et les vendeurs de diamants.  
  
La base de donnée contient 10 variables : 
\begin{itemize}
\item \textbf{price} : le prix du diamant en dollars américains
\item \textbf{carat} : le poids du diamant en carats
\item \textbf{cut} : la qualité de la coupe du diamant (Fair, Good, Very Good, Premium, Ideal)
\item \textbf{color} : la couleur du diamant (de J, la plus jaune, à D, la plus blanche)
\item \textbf{clarity} : la pureté du diamant (I1 (inclusions visibles à l'oeil nu), SI1 (petites inclusions), SI2 (inclusions visibles à l'oeil nu), VS1 (inclusions très petites), VS2 (inclusions petites), VVS1 (inclusions très très petites), VVS2 (inclusions très petites))
\item \textbf{depth} : la profondeur totale du diamant en pourcentage de la largeur moyenne
\item \textbf{table} : la largeur du plateau du diamant en pourcentage de la largeur moyenne
\item \textbf{x} : la longueur en millimètres
\item \textbf{y} : la largeur en millimètres
\item \textbf{z} : la profondeur en millimètres
\end{itemize}


```{r, results='asis', echo=FALSE}
kable(head(diamonds), caption = "Tableau des 6 premières observations de la base de données diamonds")
bdd_diamonds <- diamonds 
```

# Construction du modèle RLM complet 

Nous cherchons à trouver parmi les 9 caractéristiques que nous avons dans la base de données, celles qui expliquent le mieux le prix des diamands.  
Cela se traduit par la recherche des variables explicatives qui décrivent le mieux notre variable cible. 
  
Dans un premier temps, nous allons étudier le modèle complet, celui contenant toutes les variables explicatives. 

```{r}
RLM <- lm(price ~ ., data = diamonds)
summary(RLM)
```

On observe que toutes les variables sont significatives sauf clarity^6, y et z. 

## Non-corrélation des erreurs 

Nous voulons tester si les erreurs sont corrélées ou non. Pour cela on utilise les le test de _Durbin-Watson__ . 
$$ H_0 : \text{les erreurs sont non-corrélées} $$ 
$$ H_1 : \text{les erreurs sont corrélées} $$ 
```{r}
acf(RLM$residuals, main="Auto-corrélations des erreurs") # la fonction d auto correlation des erreurs 
```

```{r}
dwtest(RLM, alternative = c("two.sided"))
```

La p-value est significative donc on rejette l'hypothèse nulle, les erreurs sont donc corrélées. 


## Homoscédasticité

Nous voulons vérifier l'hypothèse d'homoscédasticité. Pour cela on utilise le test de __Breusch-Pagan__ .

$$ H_0 : \text{l'erreur est homoscédasticique} $$ 
$$ H_1 : \text{l'erreur est hétéroscédasticique} $$ 

```{r}
plot(RLM, 3, main="Homoscédasticité")
bptest(RLM, studentize = FALSE) 
#on obtient p-value < 2.2e-16, on rejtte donc H_0, 
```

On obtient une p-value significative donc on rejette l'hypothèse nulle. L'erreur est donc hétéroscédasticique.

## Linéarité

Nous voulons tester l'hypothèse de linéarité entre la variable réponse __price__ et les variables explicatives. Pour cela nous allons appliquer une régression linéaire local des résidus en fonction des valeurs ajustées. 

```{r}
plot(RLM, 1, main="Linéarité entre les variables")
```

La courbe rouge représentant la droite d'ajustemant, elle approche légèrement la courbe horizontale en pointillée. Cela nous permet de valider la linéarité entre les variables. On estime donc que la linéarité de ce modèle est vérifiée. 

## Normalité 

On veut tester la normalité de l'erreur du modèle. Pour cela nous allons faire des visualisation graphique puis utiliser le test de __Kolmogorov-Smirnov__ .

$$ H_0 : \text{l'erreur est normale} $$ 
$$ H_1 : \text{l'erreur n'est pas normale} $$ 
```{r}
plot(RLM, 2)
# histogramme versus densité normale
```

On observe que les points ne se situe pas autour de la droite en pointillée, cela veut dire que l'erreur ne suit pas une loi normale. 

```{r}
residus <- RLM$residuals
hist(residus, freq = FALSE,
     main = "Histogramme des résidus")
curve(dnorm(x, mean = mean(residus), sd = sd(residus)), 
      col = 2, lty = 2, lwd = 2, add = TRUE)
```
La courbe rouge représentant la densité de la loi normale, on observe que l'histogramme ne suit pas la même tendance donc cela confirme bien que l'erreur ne suit pas une loi normale.  
  
Nous allons effectuer le test de __Kolmogorov-Smirnov__ pour vérifier l'hypothyèse. 

```{r}
ks.test(residuals(RLM), "pnorm")
```
La p-value est significative donc on rejette l'hypothèse nulle, l'erreur ne suit pas une loi normale. 

# Classement des variables explicatives 

Dans cette partie, nous allons classer les variables explicatives de la plus significative à la moins significative selon les valeurs des p-values du test de Fisher.  

```{r}
tests.Fisher <- anova(RLM)
m <- nrow(tests.Fisher)
vect.pvalues.Fisher <- tests.Fisher[1:m-1,"Pr(>F)"] #Extrait le vecteur des p_values
names(vect.pvalues.Fisher) <- rownames(tests.Fisher[1:m-1,])
sort(vect.pvalues.Fisher) #Attention pour les variables explicatives qualitatives ayant
#plus de deux modalités (on compare à dimension égale)
#dans ce cas il faudrait faire comme suit
XX <- model.matrix(price ~., data = diamonds)[,-1] #Cette fonction construit la matrice de design en remplaçant 
#chacune des variables qualitatives par les indicatrices 
#de ses modalités (la première modalité est supprimée)
#on supprime la première colonne correspondant à l'intercept
``` 
On observe que les variables les plus significatives sont __carat__ , __cut__ , __color__ , __clarity__ , et __x__ .  
Celle qui est la moin significative est __y__ . 

# Influence des outliers 

Dans cette partie nous essayerons de détecter les variables qui ont des outliers et des points leviers extrêmes. Un petit changement à leur niveau peut engendrer de grands changements.  
Afin de mesurer l'influence d'une observation dans le modèle, nous pouvons se servir de la distance de Cook. 

```{r}
par(mfrow=c(1,2))
plot(RLM,4, main = "Cook distance") # distance de Cook
abline(h=4/(53940-9-1), col=c("blue"), lty = 2, lwd=3)
# Outliers et points leviers extrêmes
plot(RLM,5, main = "")
abline(h=c(-3,3), v=2*(9+1)/53940, col=c("blue","blue","green"),lty=c(2,2,2),lwd=c(3,3,3))
```

Une observation est considérée comme excessivement influente si sa distance de Cook est supérieure à $4/(53940-9-1) = 7.417022e-05$.  
On observe ici que les diamants n°24 068, 27 416 et 48 411 sont excessivement influente.  
  
Tout les points ayant un résidus studentisés supérieur à 3 en valeur absolu sont considérés comme des outliers. 
Les diamants n°24 068 et 48 411 sont donc des outliers. 

Tout les points ayant un point levier supérieure à $2*(9+1)/53940 = 0.0003$  sont considérés comme des points leviers extrêmes. 

Ici, on remarque que les diamants n°24 068 et 48 411 ont une influence supérieure à celle du reste des diamants.  

# Sélection du meilleur modèle 

Afin de trouver le meilleur modèle, une multitude de méthodes de sélection de modèle existe. Nous allons donc tester les deux méthodes qui nous semblent être les plus pertinentes, il s'agit de la méthode exhaustive et génétique. 

## Méthode exhaustive 

Une méthode de sélection est l'algorithme exhaustive. Nous allons nous baser sur les critères de l'AIC et du BIC.  
  
Selon le critère de l'AIC, le modèle sélectionner est : 

```{r, echo=FALSE, include=FALSE, eval = FALSE}
select.modele.aic <- glmulti(price ~., data = bdd_diamonds, level = 1, 
                             fitfunction = lm, crit = "aic", plotty = FALSE, method = "h")
modele.opt.aic <- summary(select.modele.aic)$bestmodel
```

```{r, eval = FALSE}
modele.opt.aic
```
$$ \text{"price ~ 1 + cut + color + clarity + carat + depth + table + x + z"} $$ 

Selon le critère du BIC, le modèle sélectionné est : 

```{r, echo=FALSE, include=FALSE, eval = FALSE}
select.modele.bic <- glmulti(price ~., data = bdd_diamonds, level = 1,
                             fitfunction = lm, crit = "bic", plotty = FALSE, method = "h")
modele.opt.bic <- summary(select.modele.bic)$bestmodel
```

```{r, eval = FALSE}
modele.opt.bic
```
$$ \text{"price ~ 1 + cut + color + clarity + carat + depth + table + x"} $$ 


## Méthode génétique 

Une autre méthode de sélection est l'algorithme génétique. Nous allons nous baser sur les critères de l'AIC et du BIC.  
  
Selon le critère de l'AIC, le modèle sélectionner est : 

```{r, echo=FALSE, include=FALSE, eval = FALSE}
select.mod.gen <- glmulti(price ~ ., data = bdd_diamonds, level = 1, method = "g", 
                          fitfunction = lm, crit = 'aic', plotty = F)
aic.best.model <- summary(select.mod.gen)$bestmodel
```
```{r, eval = FALSE}
aic.best.model
```
$$ \text{"price ~ 1 + cut + color + clarity + carat + depth + table + x + z"} $$ 

Selon le critère du BIC, le modèle sélectionné est : 

```{r, echo=FALSE, include=FALSE, eval = FALSE}
select.mod.gen <- glmulti(price ~ ., data = bdd_diamonds, level = 1, method = "g", 
                          fitfunction = lm, crit = 'bic', plotty = F)
bic.best.model <- summary(select.mod.gen)$bestmodel
```

```{r, eval = FALSE}
bic.best.model
```
$$ \text{"price ~ 1 + cut + color + clarity + carat + depth + table + x"} $$ 

Nous avons trouvé plusieurs modèles selon les méthodes et les critères. Pour la suite de l’étude, nous allons estimer les erreurs de prévision de ces modeles afin de sélectionner celui qui est le plus optimal. 

# Estimation de l'erreur de prévision des modèles sélectionnés

Nous estimerons correctement l’erreur théorique de prévision de chaque modèle, afin de choisir le modèle ayant l’erreur estimée la plus faible. Les méthodes de validation croisée permettent d’´évaluer efficacement cette erreur. On présente ici trois méthodes différentes : méthode de l’ensemble de validation, méthode K-fold CV et méthode LOOCV. 

__Modèle 1 :__ price ~ 1 + cut + color + clarity + carat + depth + table + x  
__Modèle 2 :__ price ~ 1 + cut + color + clarity + carat + depth + table + x + z  

## Méthode de l'ensemble de validation 

La méthode de l’ensemble de validation est une méthode d’apprentissage et de validation. C’est pourquoi, on a commencé par séparer la base de données en 2 parties, la première contient les 2/3 de la base, ces données seront utilisées pour l’apprentissage et le restant pour tester les prédictions en évaluant la valeur de l’erreur.  
Puisque la base de données a été séparé en deux, on peut supposer que l’estimation de l’erreur n’est pas totalement fiable. Donc, pour avoir une meilleure estimation de l’erreur, on a estimé 1000 fois l’erreur en prenant à chaque fois de nouvelles valeurs dans la base de données d’apprentissage, donc la régression linéaire change et donc les valeurs prédites également.   
On a donc cherché la meilleure estimation de l’erreur pour chacun des 2 modèles qu’on a sélectionné précédemment. Pour avoir une idée visuelle, pour voir comment varie l’estimation de l’erreur en fonction des itérations on a tracer les graphiques pour chaque modèle :   

```{r, echo=FALSE}
n <- nrow(diamonds) # nombre d'observations
M <- 1000
erreur_modele1 = NULL
erreur_modele2 = NULL
for (i in 1:M)
{
  indices <- sample(x = n, size = trunc((2/3)*n), replace = FALSE)
  ensemble_apprentissage <- diamonds[indices, ]
  ensemble_validation <- diamonds[ - indices, ]
  modele1 <- lm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x, data = ensemble_apprentissage)
  modele2 <- lm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x+z, data = ensemble_apprentissage) 
  valeurs_predites1 <- predict(object = modele1, newdata = ensemble_validation)
  erreur_modele1[i] <- mean((ensemble_validation$price - valeurs_predites1)^2)
  valeurs_predites2 <- predict(object = modele2, newdata = ensemble_validation)
  erreur_modele2[i] <- mean((ensemble_validation$price - valeurs_predites2)^2)
  }
Err1 = NULL
Err2 = NULL
for (m in 1:M)
{Err1[m] = mean(erreur_modele1[1:m])/10000000
Err2[m] = mean(erreur_modele2[1:m])/10000000
}

plot(Err1, type = 'l', main = "Erreurs de prévision", xlab = "M", ylab = "Erreur", col = "red", lwd = 2)
lines(Err2, type = 'l', col = "blue", lwd = 2)
legend("bottomright", legend = c("Modèle 1", "Modèle 2"), col = c("red", "blue"), lty = 1, bty = "n")
```

```{r}
Erreur_prevision_modele1 = Err1[M]
Erreur_prevision_modele2 = Err2[M]
print(c("Résultats des estimations par la méthode de l'ensemble de validation : ",
        paste("Estimation de l'erreur du modele1 = ", as.character(Erreur_prevision_modele1)),
        paste("Estimation de l'erreur du modele2 = ", as.character(Erreur_prevision_modele2))))
```


On observe donc que plus le nombre d’itérations augmente, plus l’erreur se stabilise et donc approche au mieux l’erreur réelle. Le modèle 1 possède une plus faible erreur que le deuxième modèle selon la méthode d’apprentissage/validation.   
    
Nous allons effectuer une autre méthode pour vérifier ce résultat. 

## Méthode LOOCV 

La méthode leave-one-out Cross-Validation est l’une des méthodes de re-échantillonnage qui va nous servir à estimer l’erreur théorique de notre modèle RLM. Elle permet également de sélectionner le meilleur modèle tout en évitant le problème de sur-ajustement. Le meilleur modèle est donc celui qui possède la plus faible erreur estimée.

Algorithmiquement cela se calcule de cette façon : 

```{r, echo = TRUE, eval = FALSE}
n <- n <- nrow(diamonds) # nombre d'observations
modele1 <- glm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x, data = bdd_diamonds)
estimation_erreur_modele1 <- cv.glm(data = bdd_diamonds, glmfit = modele1, K = n)$delta[1] #estimation de l'erreur du modele1 par la méthode LOOCV

modele2 <- glm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x+z, data = bdd_diamonds)
estimation_erreur_modele2 <- cv.glm(data = bdd_diamonds, glmfit = modele2, K = n)$delta[1]  #estimation de l'erreur du modele2 par la méthode LOOCV

print(c("Résultats des estimations par LOOCV : ",
        paste("Estimation de l'erreur du modele1 = ", as.character(estimation_erreur_modele1)),
        paste("Estimation de l'erreur du modele2 = ", as.character(estimation_erreur_modele2)))) 
```

Dans notre cas, n étant le nombre d'observations qui correspond à $53 940$ l'algorithme prend beaucoup de temps à s'éxecuter. Ce n'est donc pas une méthode à privilégier dans notre étude.   
    
Essayons alors une autre méthode. 

## Méthode K-fold cross validation

La méthode K-fold cross validation consite à diviser de manière aléatoire les données en K (ici K=10) groupes et de répéter le calcul de l’erreur K fois en prenant le premier groupe comme ensemble de validation et les K-1 pour ajuster le modèle. On remarque de plus que si on prend le même K que dans la méthode LOOCV alors on trouve le même résultat.    
Nous appliquons donc cette méthode aux deux modèles selectionnés dans l’objectif de trouver le meilleur modèle pour notre jeu de données.   

```{r}
modele1 <- glm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x, data = bdd_diamonds)
modele2 <- glm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x+z, data = bdd_diamonds)
estimation_erreur_modele1 <- cv.glm(data = bdd_diamonds, glmfit = modele1, K = 10)$delta[1]/10000000 #estimation de l'erreur du modele1 par la méthode  K-fold CV
estimation_erreur_modele2 <- cv.glm(data = bdd_diamonds, glmfit =  modele2, K = 10)$delta[1]/10000000 #estimation de l'erreur du modele2 par la méthode K-fold CV

print(c("Résultats des estimations par 10-fold CV : ",
        paste("Estimation de l'erreur du modele1 = ", as.character(estimation_erreur_modele1)),
        paste("Estimation de l'erreur du modele2 = ", as.character(estimation_erreur_modele2))))
```
On observe une erreur semblable l'une à l'autre.  

## Bootstrap 

Le Bootstrap est un outil performant pour évaluer l’incertitude d’un estimateur ou d’une méthode d’apprentissage. Nous allons l’utiliser pour estimer l’erreur théorique de notre modèle, c’est à dire évaluer l’efficacité de notre estimateur.

### Modèle 1 

```{r}
f_estimateurs_w <- function(data, index){return(coef(lm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x, data = data, 
                                                        subset = index)))}
f_estimateurs_w(data = diamonds, index = 1:53940)

f_estimateurs_w(data = diamonds, index = sample(53940, 53940, replace = TRUE))

f_estimateurs_w(data = diamonds, index = sample(53940, 53940, replace = TRUE))

boot(data = diamonds, statistic = f_estimateurs_w, R = 2000)
```

Ensuite, on fait une comparaison des valeurs de notre estimateur et celles de la régression linéaire.

```{r}
#comparaison avec les estimations des écarts-type données par la lm() 
modele <- lm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x, data = diamonds)
summary(modele)
```

### Modèle 2 

Même chose pour le second modèle : 

```{r}
##############utilisant Bootstrap -modele2#################
f_estimateurs_w <- function(data, index){return(coef(lm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x+z, data = data, 
                                                        subset = index)))}
f_estimateurs_w(data = diamonds, index = 1:53940)

f_estimateurs_w(data = diamonds, index = sample(53940, 53940, replace = TRUE))

f_estimateurs_w(data = diamonds, index = sample(53940, 53940, replace = TRUE))

boot(data = diamonds, statistic = f_estimateurs_w, R = 2000)

#comparaison avec les estimations des écarts-type données par la lm() 
modele <- lm(formula = price ~ 1+cut+color+clarity+carat+depth+table+x+z, data = diamonds)
summary(modele)
```
 
On trouve de légère différence au niveau de certaines valeurs, l'erreur données par
notre estimateur est plus élevée que celle donné par la fonction lm. De plus, pour chacun des deux modèles l’estimateur de la variance est élevé et celui du biais est faible : c’est le résultat lorsqu’on est grande dimension.    
Par le résultat de la régression, on choisit le premier modèle. Ce modèle semble être le meilleur, de plus il a été sélectionné par d'autres méthodes utilisées précédémment et il possède un biais faible : le but étant en général de diminuer le biais.

\newpage
# Conclusion 

En analysant plusieurs méthodes de sélection de modèles et en estimant les erreurs de prévision, nous avons conclu que le prix d'un diamant peut être expliqué par différents facteurs clés. Ces facteurs comprennent la qualité de la coupe, la couleur, la pureté, le poids, la profondeur, la largeur et la longueur du diamant.      
      
La qualité de la coupe joue un rôle important dans la détermination du prix d'un diamant. Une coupe précise et de haute qualité peut augmenter sa brillance et sa valeur. De même, la couleur du diamant est un autre aspect essentiel. Les diamants incolores ou légèrement colorés sont généralement considérés comme plus précieux que ceux qui présentent une teinte plus prononcée.     
      
La pureté du diamant est également un facteur significatif. Les diamants sans imperfections visibles sont considérés comme plus purs et plus précieux. De plus, le poids du diamant, exprimé en carats, joue un rôle majeur dans sa valorisation. Les diamants plus lourds ont tendance à être plus coûteux, tout en tenant compte des autres critères de qualité.      
     
La profondeur, la largeur et la longueur du diamant sont des mesures qui influencent également son prix. Ces dimensions affectent la manière dont la lumière interagit avec la pierre, ce qui peut avoir un impact sur son éclat et sa valeur.      
      
          
            
Pour conclure, à travers notre étude, nous avons constaté que le prix d'un diamant est fortement influencé par la qualité de la coupe, la couleur, la pureté, le poids, la profondeur, la largeur et la longueur du diamant. Comprendre ces facteurs peut nous aider à mieux évaluer et apprécier la valeur d'un diamant lors de son estimation ou de son achat.      